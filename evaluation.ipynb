{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124a649b",
   "metadata": {},
   "source": [
    "**Assignment 2 - Garbage Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import toch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metric import confusion_matrix, classification_report\n",
    "\n",
    "from config import OUT_DIR, CLASS_NAMES, TRAIN_DIR, VAL_DIR, TEST_DIR, set_seed\n",
    "from preprocessor import transform, build_vocab_from_dirs, ImageTextGarbageDataset\n",
    "from model import EfficientNetV2MMultimodalClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for reproducibility\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"Classes\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7259136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the vocabulary from training and validation data\n",
    "VOCAB = build_vocab_from_dirs([TRAIN_DIR, VAL_DIR], CLASS_NAMES)\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "print(\"Vocabulary size:\", VOCAB_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageTextGarbageDataset(TEST_DIR, transform[\"test\"], VOCAB, CLASS_NAMES)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0,\n",
    "                         pin_memory=(device.type == \"cuda\"))\n",
    "print(\"Test dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df59d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the trained model\n",
    "MODEL_PATH = os.path.join(OUT_DIR, \"best_model.pth\")\n",
    "print(\"Checkpoint exists:\", os.path.exists(MODEL_PATH))\n",
    "\n",
    "model = EfficientNetV2MMultimodalClassifier(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_classes=len(CLASS_NAMES)\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ff43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run predictions on the test set\n",
    "all_preds, all_labels, all_paths, all_texts = [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        text_vec = batch[\"text_vec\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(images, text_vec)\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_paths.extend(batch[\"path\"])\n",
    "        all_texts.extend(batch[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5db0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print overall accuracy and calissification report\n",
    "accuracy = 100 * (np.array(all_preds) == np.array(all_labels)).mean()\n",
    "print(f\"\\nAccuracy on test set: {accuracy:.2f}%\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title(\"Confusion Matrix (Test)\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "plt.savefig(os.path.join(OUT_DIR, \"confusion_matrix.png\"), dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f102e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Misclassified examples figure\n",
    "misclassified = {name: [] for name in CLASS_NAMES}\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "for i, (y, p) in enumerate(zip(all_labels, all_preds)):\n",
    "    if y != p:\n",
    "        true_name = CLASS_NAMES[y]\n",
    "        pred_name = CLASS_NAMES[p]\n",
    "\n",
    "        img = Image.open(all_paths[i]).convert(\"RGB\")\n",
    "        img = transform[\"test\"](img).cpu().numpy().transpose(1,2,0)\n",
    "        img = (img * std) + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        misclassified[true_name].append({\n",
    "            \"image\": img,\n",
    "            \"true\": true_name,\n",
    "            \"pred\": pred_name,\n",
    "            \"text\": all_texts[i]\n",
    "        })\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "rows = len(CLASS_NAMES)\n",
    "for row, cname in enumerate(CLASS_NAMES):\n",
    "    examples = misclassified[cname]\n",
    "    if len(examples) == 0:\n",
    "        continue\n",
    "    selected = random.sample(examples, min(3, len(examples)))\n",
    "    for col, ex in enumerate(selected):\n",
    "        plt.subplot(rows, 3, row*3 + col + 1)\n",
    "        plt.imshow(ex[\"image\"])\n",
    "        plt.title(f\"True: {ex['true']}\\nPred: {ex['pred']}\\n{ex['text'][:20]}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"misclassified_examples.png\"), dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions to CSV\n",
    "df = pd.DataFrame({\n",
    "    \"path\": all_paths,\n",
    "    \"text\": all_texts,\n",
    "    \"true\": [CLASS_NAMES[i] for i in all_labels],\n",
    "    \"pred\": [CLASS_NAMES[i] for i in all_preds],\n",
    "})\n",
    "csv_path = os.path.join(OUT_DIR, \"test_predictions.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(\"Saved predictions CSV:\", csv_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
